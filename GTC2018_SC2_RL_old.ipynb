{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thoughts -- frame stacking [ future frame prediction ]\n",
    "# conv-lstm vs fc-lstm\n",
    "# multiple agents\n",
    "# loss function weights @ value, policy [ actions & action params]\n",
    "# fix end of trajectory states [ not being updated ] -- roll over last trajectory end to new ?\n",
    "# multi step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "# required \n",
    "from absl import flags\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(['--'])\n",
    "\n",
    "# note this import must happen after flag initialization\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions\n",
    "from pysc2.lib import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "envParams = { 'screenResX': 64,\n",
    "             'screenResY': 64, \n",
    "             'screenResX_minimap': 32,\n",
    "             'screenResY_minimap': 32,\n",
    "             'visualizeFlag': True\n",
    "            }\n",
    "\n",
    "env_args = dict(\n",
    "        map_name='DefeatRoaches',\n",
    "        step_mul=1,\n",
    "        game_steps_per_episode=0, # no limit\n",
    "        screen_size_px = ( envParams['screenResX'], envParams['screenResX']), \n",
    "        minimap_size_px = ( envParams['screenResX_minimap'], envParams['screenResY_minimap']),\n",
    "        visualize = True,\n",
    "        score_index = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = sc2_env.SC2Env(**env_args) # ** syntax implies variable number named arguments\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Observation  [ contains entire state ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 15 10:51:27 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   47C    P8    28W / 149W |      1MiB / 11439MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEkAAAEnCAYAAABVIx3AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmcZVV97/3Pl6GZREVRSQMNURRFvaIJYQhEHJBoJOhzBYKCgkNEE4c8OETUiAMO0YQ43DyaGJn6IuN1xiBGQQYBh7QJQ7hpxoZmblpoJhHW88daVX04far6VHVVnapTn/frVa/a5+x99l57rz2s/dtrrZ1SCpIkSZIkSfPdeoNOgCRJkiRJ0mxgkESSJEmSJAmDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCZijQZIk1yV56SR+d3mSvadzGZq8JN9P8oY+pluV5Klt+Pgkn5jotEn2SnLVVKVdkrSmJHsnuXHQ6eg0XllgNqZ3OgzDeiY5Osnidfh932VC9Zbky0k+POh0aHok2T5JSbLBgNOxTsf6sJrs8be27TmIc+NsPB8PdKefaaWUZw86DRpbKeXlfU73mAnMs+e0pZTzgR1HPie5DnhzKeWH/c5bkjT3WBaYf5IcD9xYSvnQyHfuB+uulHLEyHC7wVlcStlmbb9LcjSwQynlkOlLnWYLy9jTY7LHXx/zHT03ztSxOpHz8UztT3OyJokkrc2gn3xobkrltXEO89ifnSaSL+ahJGmQ5nJBcOck/5Hk10lOTbIxQJJXJlmSZGWSi5L8j5EfdDahSbJJkhOS3JXkyiTv61H1tOcyxjJSfbXN67YkNyd5VZJXJPm/SVYkOapj+j9I8tOW1puTfCnJgo7xJck7k1yT5I4kn53rhfck709yRtd3n0/yhSTnJnlz+26HJOe1bX9HklM7pi9JduiYxZZJzklyT/vNduNMO/L9aFXjJCcBi4DvtOY570vyvSTv6PrNfyR59VrWryR5e5L/bun5eJKntX3x7iSnjeRxki2SfDfJ7W0//G6SbTrmdW6STyW5tP32W0me0MdmHnpJtk3yf9q2u7MdO4cluTDJsUnuBI5u076xHeN3JTm7a/94Ztt3ViS5KsmBHeOOT63K2HPf0tRq5+cPJLmi5dVxHef1tyRZ2vLp20kWtu8/muSLbXjDJPcm+Wz7vEmSB0aOmSS7teNwZZJfpaNaZzvWjklyIXAf8NQZXv05b7z865rur5Nc3Y6pK0bOqUkWtPx9bse0T05yX5Intc9ru76/P8l/APdmnJvsrFkWOL6l+Qpgl6nbKoM3B/PlUdMmWZjkzHauvzbJO8f5/elJbkktN/wkybPb938OvA54X+o1/jsdy3tpW8b96bi+Jnl+atljw/Z5zOvIXJeuclIe3TR5pFx7ZFaXaw/vnjbJZsD3gYVtG68aOU/3WN4fA0cBB7XpfpXkgCS/6Jru/03yrY7ljHk9zjjXcq3Wjq+b2ja8KslLkqzXcfzfmVpO7VnWTPK4JP/S9oObWt6v3zH+Le04GTmPvCA9ytht2vGuyb/b8vieJOcAW07vlhmcmT7+OixIcmLbxpcn+f2O+Y6cG9c4VteyLuPetyT507aslW3aZ3Uvsw0f3fbDNdLXa39KsnGSxW3/XZnkZ0mestaNvzallDn3B1wHXAosBJ4AXAkcATwfuA3YFVgfeEObdqOO3720DX8aOA/YAtgG+A9qVcxxl7GWdO0N/Bb4G2BD4C3A7cDJwObAs4H7gd9t0/8esBu12dP2bRnv7phfAX7clr8I+L/U6kUDz4N1yLvtqDchm7fP6wM3t+1w7sj6AV8HPkgN5G0M7Nm1XXZow8cD9wB/BGwEfB64YJxpP9GRV935/dKOzwcCl3R8fh5wJ7BgLetXgG8Bj235/SDwb9SbrscBVwBvaNM+EfifwKZt/zgd+GbHvM4FbgKeA2wGnEmtSjfwfBzwPrQ+8Cvg2LZdNgb2BA5rx9872jG1CbA/sBR4VvvuQ8BFbT6bAcuAw9u45wN3ADv1s2/5N+X5eh1wGbBtO+ddCHwCeHHLlxe0fPgi8JP2mxcD/9mG9wCuHjlu27hfteGt2/H7inZO2ad9flIbfy5wQztmNwA2HPT2mGt/4+Rf97n2AOp1dT3gIOBe4HfauH8EPtMx7buA77Thfq7vS9ryN+kjrZ1lgfNbmrdt63DjVGyT2fA3B/NldNqWll9Qy1QLqNfRa4B92/RH03FNBN5IvZZuBPwDsKRj3PG06/8Y+8GPgLd0jPss8OU2POZ1ZBj+6CgndW8rVpdrP0Yt176CWobbYoxp+zp2euTdRsAK4Fkd3/078D87ltPzesxaruX+jW7PHdt2Wtg+bw88rR3PF1PvhTYCvgJ8vWOaAmzQPn+jjd8MeDL1PumtbdwB1DLrLkCAHYDt2rjRY619Xts1+afA37f0/FHL+6Es/w7w+HugzW994FPAxR3jR/Or+1hdy3zPZYz7FuAZ1OvKPm1d3kc9ry4YY5l9pa99fivwHer91PrU++vHrmvezOVaCV8opSwvpaygbpidgT8HvlJKuaSU8nAp5QTqTepuPX5/IPDJUspdpZQbgS/0uYy1eQg4ppTyEHAKNfr5+VLKPaWUy6k3yc8DKKX8opRycSnlt6WU66gnnhd2ze8zpZQVpZQbqBf9g/tIw6xVSrke+CUwUiPjxcB9pZSLuyZ9iBpQWVhKeaCUcsE4s/1eKeUnpZQHqYGV3ZNsu45J/TbwjCRPb58PBU4tpfymj9/+bSnl7pbflwE/KKVcU0r5NTXS+3yAUsqdpZQzSyn3lVLuAY5hzfw/qZRyWSnlXuDDwIGdUft56g+ohfn3llLu7do/lpdSvtiOqfupwdNPlVKuLKX8FvgktYbYdsArgetKKce16f+dekI/oGNZ07FvaWxfKqUsa+fcY6jnu9cBXyul/LLlwweo+bA9tSD19CRPpBak/gXYOsljqMfSeW2+hwBnlVLOKqU8Uko5B/g59QI84vhSyuVtX3ho+ld1KPXKv0cppZzerquPlFJOBf6bekwDnAAcnCTt86HASW24n+v7F9ry759Amg+kXrNXlFKW0bssMNfNpXzpnHYX6k3Tx0opvymlXAP8M/BnvX5YSvlaK2s9SC1kPy/J4/pYJtSHWQdDbXLXlnFyGzfedWQ+eAj4WCnloVLKWcAqOvp0mwotz06lnqtJrQW0PfDdjsnGuh73cy0XPEwNOuyUZMNSynWllKup+/cHSyk3dhw7r0lXra/2ZP4V1Ie595ZSbqM+rBo5Ht9MLf/+rFRLW5m/lzGvyUkWUY/9D5dSHiyl/IR6DzZfTdfxd0Hb/g9Tz+fPm4J5wtj3LQdRj+FzWhnrc9Rg+B5TkL6HqA+ed2jXoV+UUu5e1xWZy0GSWzqG7wMeQ72pPrJVtVmZZCX1iUSvKkcLqRHVEct6TNNrGWtzZ8tQqLVGAG7tGH//yHySPCO1icUtSe6mXni7q5R1put6eq/LXDNaGAFey+qCSKf3USPRl7ZqVm8cZ36j26iUsor6NGKdtlMp5QHaBTu1idPBrC4Urk13fo+V/5sm+UqS61v+/wR4fFcQpDv/N2SIqx32aVvg+lZY7dZ9HG8HfL7jfLCCul9t3cbt2nW+eB2wVa/5TdW+pXH1Ot8tbMPAaD7cCWzdbqR+Tg2I/BE1KHIR8Ic8OkiyHXBAV17vCfzOGMvW5Kz1epXk9VndNGMl9YnTlgCllEuo19q9kzyT+iTy2+2n/VzfJ5OH3WWBsQr1c9lcypfOabejVh/vnPdRwBrVqJOsn+TTqU0G7qY+aYT+r5dnUm+6f4d6LnmEWsNoJB1jXUfmgzu7rrf9locn6gTgtS1IdShwWrtpHzHW9bifa/m8V0pZCrybGgS5LckprUnGdsA3OrbdldSASvdxth21DHpzx7RfodYogXrcX91ncsa7Ji8E7mo32SOG8bzcr+k6/rrvcTfuDoxN0lj3Ld1luUfatGOdRyeSvpOAs4FTkixP8rdpTSXXxbB1jLWM+kTomD6mvZlateyK9nkQT4f/P2p1woNLKfckeTfwmq5ptgUub8OLgOUzmL7pcjrwd6n9b7wa2L17glLKLdTmSiTZE/hhkp+0k3y30bxrT5CfwMS3U+nx3QnUA+8Cam2Xn05wnmtzJDUavGsp5ZYkO1P3h3RM07lfLqJGS++Y4nTMNcuARUk26BEo6c7HkXPC/+6eSXsKeF4pZZ9xljUV+5b6172/L29/nW3PN6M+MbipfXUetUba84Gftc/7Up+C/6RNs4z6dOMt4yy71zlAE9Mr/0a1Y+6fgZcAPy2lPJxkCY8+551Afcp4C3BGC1hDf9f3yeThzax5nR02cylfOqddBlxbSnn6WBN3eC21WcxLqQGSxwF3sXodxk1DKeWuJD+gPu18FnBKKWXkN2NeR4bEfdRq6iO2AibzeujJ5nP9opSLk/wG2Iuan6/tmmSs6/Ey1n4tF1BKORk4OcljqQGOz1C33xtLKRd2T99qbI5YRq0ltuU4D6meNtaie0zb85rczkdbJNmsI1CyqMc8hsUgjr/pnO9Y9y3Lgc6+rdKmvYmJe1SaWs2UjwIfbfvsWcBV1NrFkzaXa5L08s/AEUl2TbVZkj9JsnmPaU8DPpDaeebWwF/ObFKB2nb2bmBVezrzth7TvLelcVtqu8FTe0wzp5RSbqe2WzuOWgC6snua1E68RjoxvYt6QDwyxixfkWTP1A5RP05ttzbRJ4q30tVZYwuKPAL8Hf3XIpmIzak1S1amdmz0kR7THJJkpySbUtskntFRU2m+upR6Y/PpdoxvnOQPx5j2y9TjfKQDv8clGamC+11qk6pDUzv93DDJLunoSIqp2bfUv79Isk07Hj5IPd99HTg8yc5JNqLWuLuk1CaKUIMirweuKLU53LnUar/XtnMNwGJgvyT7tifOG6d2iLbOr8rTo/TKv06bUc/ltwOkdkD3nK5pFlOD54cAJ3Z8P5Hr+0R0lgW2ofZpNGzmYr5APdffk9rZ5Cbt2H1Okl6d625OvYG7k3rD8cmu8Wtc43s4mXoueQ2PruE63nVkGCyh1uBYP7Wjxu5mv/26FXhi+mvidCuwfdZ8GcGJwJeAh8qazazHuh73cy2f95LsmOTF7Tr6ALX8+Qh1/z6mBSdI8qQk+3f/vpRyM/AD6kPOx6Z2+Pq0JCP7y1eB9yT5vXYu2CGrm6R1H39jXpNbE52fU294F6Q+KN1v6rfIrDGI42+i8+11rI5lrPuW04A/Se0seEPqg+IHqbV/J5Om0f0pyYuSPDe1Jv7d1MDMWPeMfRuqIEkp5efU2gdfot5YL6V25tjLx6iRumuBHwJnUDNrJr2HGim/h1rQ6BUA+Ra147IlwPdYx6jYLHIy9YlPr6Y2UNsjXpJkFbVa77tae+Sx5vURatXL36O1aZ2gTwEfSq32956O70+kRj4XT2Kea/MP1PZ4d1A7zfrXHtOcRO2Y6RZqB6Vj9uw/X7ST7X7UKt83UI/jg8aY9hvUJyWnpFbBvgx4eRt3D/Ayanva5dRt/Blqm90RU7FvqX8nUwth11Cr7X6ilPJDarvWM6nBsafx6D4JLqIeRyO1Rq6gFgBHPtMK0vtTq+rfTn2K9V6G7Bo4C6yRf50jSylXUIPOP6UWcp5L7Ui0c5pl1H6rCqubO0z0+j4RH6VWAb62pX06AuKDNhfzZeRc/0pqf3DXUq+VX6XWEul2IjUfb6KeA7r7OfsXal8MK5N8c4xFfht4OnBLKWX0LQ7jXUeGxLuo19SRZipjbZ9xlVL+ixrUvqZt5/Gapp7e/t+Z5Jcd359EDdD1KnP1vB73eS1X3R6fph5Ht1CbyXyA2gnut4EfJLmHeuzsOsY8Xk/tRPkK6vF+Bq3ZainldGqfRydT72u+Sa3tA11l7D6uya9taVhBzfPOwOywGcTxNxFjHatj6XnfUkq5inrMfpG6D+4H7Ff66+uxW/c921bUffFuanOx85iCa3lW1yac35K8DfizUspkI3hTLkkBnj5GExPNgCSvB/68lLLnAJZ9LrVX6K/O9LJVX61G7Sn8Q4NOy3yQ5Drq261+OOi0aOKmMv+SfI3aCbPH3joyXzSXJNmE+rakF5RS/rvj++PxeizNasN23zJsfZL0LbVzrqfS3o5ArfbzpYEmSrNKqyr2durrDyVJ0yy1PfH/Q3sLmGYH80Uz5G3AzzoDJJI0CPO5qvECaqdF9wA/ojZrWevNcJKjkqzq8ff9aU6vZlCSfalVAG+lo0lQkr3GyP9VA0usJA2BJB+nNmX4bCnl2nWYz6KxztOpr5fUBJgvmowk3x8jr48aY/rrqE0PjpzRhEpDaKLH3wTmO9Y5fK+pSvtsYXMbSZIkSZIk5ndNEkmSJEmSpFEGSSRJkiRJkpjhjlv3We8A2/bMMuc8cnqmal7m7+xj/g4383e4mb/DzfwdbubvcDN/h5v5O9z6yV9rkkiSJEmSJGGQRJIkSZIkCTBIIkmSJEmSBMxwnySaf85evmTQSZg39l2486CTIEmSJElzmjVJJEmSJEmSMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSANhg0AmQJElzz9Jjdxsd3uGvLh5gSjQd7nv1rqPDm37jkgGmRNPhho/sMTq86KMXDTAlmg5nL18yOrzvwp0HmBJNh7sO2310eIvjfzrAlAwva5JIkiRJkiRhkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAG+3UaSJE2Cb7QZbr7RZrj5Rpvh5htthptvtJl+1iSRJEmSJEnCmiSSJGkSlh672+iwtUqGz32v3nV02Folw+eGj+wxOmytkuFz9vIlo8PWKhk+dx22++iwtUqmhzVJJEmSJEmSMEgiSZIkSZIE2NxGkiRNgk1shptNbIabTWyGm01shptNbKafQRJJkjRh87FPks52/iOG9WZkPvZJMp/ydz72STKf8tc+SYbbfOyTZKaPX5vbSJIkSZIkYZBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAXwEsSZImYb689ne+mi+v/Z2v5strf+crX/s73ObLa38HySCJJEmasKXH7jY6bMBk+Nz36l1Hhw2YDJ8bPrLH6LABk+Fz9vIlo8MGTIbPXYftPjpswGR62NxGkiRJkiQJgySSJEmSJEmAzW0kSdIk2MRmuNnEZrjZxGa42cRmuNnEZvpZk0SSJEmSJAlrkkiSpEmw49bhZsetw82OW4ebHbcONztunX7WJJEkSZIkScIgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBNhxqyRJUl/sAHG4mb/DzfyV5q6ZPn4NkkiSpAnzjTbDzTfaDDffaDPcDAgNN99oM/1sbiNJkiRJkoQ1SSRJ0iQsPXa30WFrlQyf+1696+iwtUqGzw0f2WN02Folw+fs5UtGh61VMnzuOmz30WFrlUwPa5JIkiRJkiRhkESSJEmSJAmwuY0kSZoEm9gMN5vYDDeb2Aw3m9gMN5vYTD9rkkiSJEmSJGGQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJAGww6ARouPmedkmSJEnSXGFNEkmSJEmSJAySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSYJBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkAFJKGXQaJEmSJEmSBs6aJJIkSZIkSRgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSYJBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSMAuCJEm+nOTDk/jd0UkWjzP+8iR7r1PiJmgQy1xXSY5K8tVBp2NdTHYf0vQzbyYvyaIkq5KsP+i0SFK3qTq/J9k7yY1TkaZxljHnyzpTxXxTP1Idl+SuJJe2796W5NZWNnnioNMoTaeUUgadhlEtwLC4lLJNH9MeDexQSjlkKqedKUmuA95cSvnhDC5zb/rcvnPVfFjHucq8Gd8gzgmzQZIvAzeVUj4+RfPbHrgW2LCU8tse448CnlpKeXMf8zqXus+uUUhf23KGgXkzeUkWAVcAjyulPDyINMykdTm/z/S1YTbsH7OF+aaxJNkL+DqwYynl3iQbAncDu5VSfrUO890e81FzwAaDToCmRpJQg16PDDoterQkG3ghmJ1mKm/cB8ZWSjliZHgmCt2llE9O17yHjXnTv+4gZynlBuAxA02UJE3edsB1pZR72+enABsDlw8uSdLMmZLmNklKkh06Ph+f5BNteO8kNyY5MsltSW5Ocnj3tEk2A74PLGzVuFYlWbiWRS9IcmKSe1pTl9/vmO91SV6a5I+Bo4CD2jzHjX4mOTfJp5JcmuTuJN9K8oSO8X/alrWyTfus7mW24aOTnNYrfUlOAhYB32lpel+SjZMsTnJnm/fPkjylj7Qek+RC4D7gqUkOT3JlW+Y1Sd7apu25fdPVbGm89ZtOg9iHkqyX5K+TXN22+2kjeZ1k+5amNyS5IckdST44wd++KckNwI/a969Pcn2b/sMd++hWSe5LR9XFJC9Icntq5H6gzJuJ502Sw5JcmOTYJHcCRyd5WpIftWXckeR/J3l8m77XOWEkrRu0aRYm+XaSFUmWJnnLRPJR0uSMHIPDaEDn903ab+9KcgWwS9f4hUnObOfZa5O8s2PcmGWrNv79SW5q465K8pKO342UdX7S/q9saX1hO68+t2M+T27n/idNYrNOO/Nt8vmWZIsk323pvKsNb9Mx/vD0KEcPq175luRNwFeB3du2/jpwVfvJyiQjZadnJjmn5cNVSQ7smO8mSf4utWz16yQXJNmENfNx9yQ7JDmvTXdHklNnchtIvcxUnyRbAY8DtgbeBPyvJFt0TtAilS8HlpdSHtP+lq9lvn8KnAI8Hvg28KXuCUop/wp8Eji1zfN5faT39cAbgd8Bfgt8ASDJM6hVz94NPAk4i3pTs2Ai6SulHArcAOzX0vS3wBuo22hb4InAEcD9faT1UODPgc2B64HbgFcCjwUOB45N8oJ+tu8k1m8mTcc+9A7gVcALgYXAXcD/6ppmT2BH4CXA32R10Kif374QeBawb5KdgH8EXkfdr0bWhVLKLcC5wIEdvz0UOKWU8tA46Z8tzJvedgWuoT59OQYI8KmWpmdRj/Wj23J6nRO6nQLc2H7/GuCTSV68ljTMiAEV2P8gyc9Tg9m3Jvn7rklel95BtO7A8G5JLkoNDP8qY/QrlWT9JJ9r87sG+JOu8Ye1AvU9raD5ur423jQzbyaeNzHI2Wk6zu8fAZ7W/valln+AGuQGvgP8qi3zJcC7k+zb8fueZaskOwJ/CexSStm8zfu6Hsv/o/b/8S2t57X5dTbJPhj4t1LK7eOsx2xmvo1tPeA4ak2JRdSyduf9Q89y9Djzm7PGyjdqWeMI4KdtWx8MPLv97PGllBe368I5wMnAk4E/A/6xlakAPgf8HrAH8ATgfcAjrJmPPwU+DvwA2ALYBvji9K211J+ZCpI8BHyslPJQKeUsYBX15mZdXVBKOau19z0J6CcA0o+TSimXtQvIh4EDUztPPAj4XinlnHaD9DlgE+oJYF3T9xA1OLJDKeXhUsovSil395HW40spl5dSftu27/dKKVeX6jzqSWev/lZ7wus3k6ZjHzoC+GAp5cZSyoPUG9bX5NFPDT9aSrm/tb/8FavzsJ/fHl1KubeUcj/1pvY7pZQLSim/Af4G6OwQ6ATahb7tawdT95m5wLzpbXkp5Yvt2Ly/lLK0HVsPtgLc31ODNWuVZFvgD4H3l1IeKKUsoT7leX0/v58FpqPA/nng86WUx1IL7ad1jR8riDYqydbA94BPUAtx7wHOTO+nkG+hFpyfD/w+db8Zmc9m1GD6y1shfw9gyThpn03Mm97mTZBzLabj/H4gcEwpZUUpZRntQVSzC/CkUsrHSim/KaVcA/wz9QZsxFhlq4eBjYCdkmxYSrmulHJ1n2k6ATg4SdrnQ5k71+BezLcxlFLuLKWcWUq5r5RyD/X4fmHH+HUpR881/eTbWF5JbY5zXCvn/DtwJnBAC768EXhXKeWmdl9zUSuT9fIQNWi1sJVxLlj3VZPWzUwFSe4sj26Pfx9T01b3lq55bpypqRa7rGP4emBDYEtq4eb6kRGl9v+xjPbUeR3TdxJwNnBKkuVJ/jb9NbXoTCtJXp7k4va0aiXwipb2fkx0/WbSdOxD2wHfaE8pVwJXUi/Wnc2cuvPwMRP4bWfeLOz8XEq5D7izY/y3qAWE3wX2AX5dSrl0XVZuBpk3vXUfm09JckpqleK7gcVM7Nhc0QrP4yJvAAAOg0lEQVR0I65ndhyb/ZiOAvtDwA5JtiylrCqlXNw1fqwgWqdDgLNawf2RUso5wM+p581uBwL/UEpZVkpZQb1h7vQI8Jwkm5RSbi6lzJV22+ZNbwY5q+k4vz/qnEtHuYN2ozRy/m7n8KMY/9y/cWq/T0upT8GPBm5r59u1NdsGoJRySZvX3kmeCexAre0wV5lvY0iyaZKvpDYDuZva/OPx7SHIupaj55p+8m283+7a9dvXUQPvW1L7L+k32PU+aiD60tSmWG+c8JpIU2yqgiT3AZt2fN5qkvOZrlftTHS+23YML6IW+O4AllNPCsBoZ6nbAjeta5paAfWjpZSdqE+6Xkl/BajR+STZiBrF/RzwlFLK46lNZtI97Rimcv0mahD70DLq08XHd/xtXErpZ337+W1nWm6mViEEaltNas2hOmEpD1Cfth7C7HuCZd5MLm+61/eT7bvntifsh7D62Ow1faflwBOSbN7x3SJm5ticCtNRYH8T8Azgv1L7cHpl1/ixgmidtqM+9eos5O1JbXbVbcwbhFJrWhxErcV0c5LvtQL7XGDe9DZfgpyDOL/fzJrlrBHLgGu7zt+bl1J6BcfWTEQpJ5dS9qTuPwX4zATSOlJr8FDgjHbun63Mt9Ummm9HUgPBu7Zr8Ujzj/RRjh4265Jvy4Dzun77mFLK26j3TA9QaxJ2WyMfSym3lFLeUkpZCLyV2mxnhzV/Ks2cqQqSLAFem9ou+I/p8+lKD7cCT0zyuClKV+d8t2/Vv/pxSJKdkmwKfIx60n2YeqP0J0le0mp5HAk8CFw0yTQ9deRDkhcleW6LZN9NDcxM9E01C6hVFm8Hfpvk5cDLupY53vadyvWbqEHsQ18GjkmyHUCSJyXZv8/lTPS3ZwD7JdkjtY+Xo1nzonsicBi13e5sCpKYN1OTN5tTn9L/OrUpwXu7xj/qnNCp1KrNFwGfSu3k+X9Qb0QX95p+AGa8wF5K+e9S20k/mVqgPiO1acVELKM2r+ws5G1WSvl0j2nHu0GglHJ2KWUf6k38f1GrLM8G5s3k8ma+BDkHcX4/DfhAagea21D7kRpxKXBPakeem7R0PSfJLr1ntVqSHZO8uN3oPkDta6JXOer29n33+XYx8Gpq3p7Yx3oMkvm22kTzbfO2jJWpnbp/pGPc2srRw2bS+QZ8F3hGkkOTbNj+dknyrFJron8N+PvU/pjWT+2gdWTbPiofkxyQ1Z3n3kU9n/q2Tg3UVAVJ3gXsB4xUtfrmZGZSSvkvaseh17QnR31Vt+vD6e3/nUl+2cf0JwHHU592bQy8s6XvKupJ+IvUKOl+1DbIv5lEmj4FfKit53uoBdczqAGSK4HzmODNWHtK9U7qhewu4LV0VDtc2/ad4vWbqEHsQ5+nbp8fJLkHuJjaDr0fE/ptq979Dmq79JupN8u3UYNQI9NcSL0o/LKUcn2v+QyIeTM1efNR4AXAr6l9LfyfrvHd54RuBwPbU2+4vgF8pLTXjc4CM15gT3JIkie1wtjK9vVEC1WLqQGyfVvaN07tzLTXa25PA96ZZJvUPjv+uiMtT0myfwsEPEjdh2ZLAc+8mZq8GdYg5yDO7x+l1qS5ltrfw2hZpz2QeiWwcxt/B7VpUj838RsBn26/uYUapPtAj7TeR+2H4sKW1t3a98uAX1Jv0M7vY3mDZL5NPt/+gdrf3h3U8sG/dixj3HL0sFmXfGvb6mXU/kuWU/PuM9T8hNqP1H8CPwNWtHHrjZGPuwCXJFlF3d7vKrV/FGlwSin+dfxR32Tx5kGnw7/h/qNWL/8t8Ltd3//I/c+8mWt/1M4yLwfuoRacvw58oo3bG7ixa/rrgJe24eNHpm2fv0btE2YltRO3sZa5mBrMWtWW/ar2/fbUwvIGHdOOntepNYUWd4zblRqUXkF9wvU9YFGP320AHNvSdi3wFyPLodZQOI8aAFvZfrfToPPFvJlc3lBrjV3Q9d2zgV+0dVpCrWl5Y8f4/amdt66k3hw8al2pTfq+29blauCIQe8b/vXM+6917vP+zY0/880///yb6r+UMl3dgMxNSc6lFtK+Oui0aLgk2Q/4N2oV7b+j3gC8oLSDsFVvPAfYtjy67bqmmXkjSfNbku2pAbDnl1KuHWxq1C/zTdJ0mKm320xKku8nWdXj76h1nG+vea5KMute8TWX0jobTdc+NEn7U6skLgeeDvxZx034CcAPgXfPl5vwuZ43Sb48Rvq/PID0S9KsMcvO72uV5OPAZcBn5/ON9rDkW5KjxliP7w8utZLmEmuSSJJmpVag7RUQ/mQp5ZMznR6tNtfzpgUzD+kxanEp5YiZTo8kSZo9DJJIkiRJkiQxy5vbSJIkSZIkzZQNZnJh+6x3gNVWZplzHjk9UzUv83f2MX+Hm/k73Mzf4Wb+Djfzd7iZv8NtKvNXc5M1SSRJkiRJkjBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSYJBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJAA2GHQCJEmSJM2c9Z/yZB565tYArHfevw84NZI0u1iTRJIkSZIkiSGoSXL28iWjw/su3HmAKZEkSRoOS4/dbXR4h7+6eIAp0XS4f/Em/PjZxwGwz8GHW5tEkjrM+SCJJEmSpP6tOGtrXsT+ACwwQCJJj2JzG0mSJEmSJKxJIkmSJM0rC1YWbrmwdty6iOsHnBpJml2sSSJJkiRJkoQ1SSRJkqR55TlvvYzjFp0PwD4/tuNWSeo054MkvtFGkiRpavlGm+F265sW8ryXvR2Arc67aMCpkaTZxeY2kiRJkiRJDEFNkrOXLxkdtlaJJEnSult67G6jw9YqGT5XHrk5x+51IgD/dPIePHzrbQNOkSTNHnM+SCJJkiSpf9tvezs7Lbi1fthyCzBIIkmjbG4jSZIkSZLEENQksYmNJEnS1LKJzXDb5JD7+Ytn/iUA613um20kqdOcD5LMxz5JOtd5xHxZd0mSNP3mY58knes8YljX/f7Fm/DjZx8HwD4Hz49XAD/ywucDcM2rNuKp33wQYF6st6SJs7mNJEmSJEkSQ1CTRJIkSVL/Vpy1NS9ifwAWzJPaFNt8ZikA5yw6n8N33wuA5WtWHpIka5JIkiRJkiSBNUkkSZKkeWXBysItF24NwCKuH3BqZsa5V+xYBxadPzr8DH4+wBRJmq0MkkiSJEnzyHPeehnHLTofgH1+PD86bn3sfy4A4Jt7PWZ0WJJ6sbmNJEmSJEkSQ1CTxFffSpIkTa1hffWtqlvftJDnveztAGx13kUDTs3MeMFB/wnAqzZbxbfa8PJjB5kiSbPVnA+SnL18yeiwARNJkqR1t/TY1a/9MGAyfK48cnOO3etEAP7p5D14+NbbBpyi6ffLU59bB957Pks/sxMAm3LJAFMkabayuY0kSZIkSRJDUJNEkiRJUv+23/Z2dlpwa/2w5RYwD2qSPOEVN40OrzhkFQCbfmNQqZE0m835IIlNbCRJkqaWTWyG2yaH3M9fPPMvAVjv8uF/s023Jz921aCTIGkWs7mNJEmSJEkSQ1CTxI5bJUmSptZ87Lj16oO+vMZ3+/7VcJYt71+8CT9+9nEA7HPw4ax33vDXJll18sI6cAz89h+3AmAB1w8wRZJmK2uSSJIkSZIkMQQ1SSRJkqR19bRTj1jjux0Yzlo0K87amhexPwAL5kEtEoDnvPWy0eEd3n8FAMvtuFVSDwZJJEmSpHlkwcrCLRduDcCiedLk5NwrdqwDi84fHX4GPx9giiTNVja3kSRJkiRJwpokc5Id1EqSJE2t+dJBLdSmJ8ctOh+AfX48PzpufcYba62RfdnZGiSSxjXngyQGDCRJkqbWfAoYzEe3vmkhz3vZ2wHY6ryLBpwaSZpdbG4jSZIkSZLEENQkOXv5ktFha5VIkiStu6XH7jY6bK2S4XPlkZtz7F4nAvBPJ+/Bw7feNuAUSdLsYU0SSZIkSZIkhqAmiSRJkqT+bb/t7ey04Nb6YcstwJokkjRqzgdJbGIjSZI0tWxiM9wW7HM97+AP26erBpoWSZptbG4jSZIkSZKEQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSYJBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQIMkkiSJEmSJAEGSSRJkiRJkgCDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBEBKKYNOgyRJkiRJ0sBZk0SSJEmSJAmDJJIkSZIkSYBBEkmSJEmSJMAgiSRJkiRJEmCQRJIkSZIkCTBIIkmSJEmSBBgkkSRJkiRJAgySSJIkSZIkAQZJJEmSJEmSAIMkkiRJkiRJgEESSZIkSZIkwCCJJEmSJEkSYJBEkiRJkiQJMEgiSZIkSZIEGCSRJEmSJEkCDJJIkiRJkiQBBkkkSZIkSZIAgySSJEmSJEmAQRJJkiRJkiTAIIkkSZIkSRJgkESSJEmSJAkwSCJJkiRJkgQYJJEkSZIkSQLg/wc+/m+mfdY2mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe00a5c03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numScreenLayers = obs[0].observation['screen'].shape[0] # 17\n",
    "\n",
    "plt.figure(figsize=(19,5))\n",
    "titles = ['heigh_map', 'visibility_map', 'creep', 'power', 'player_id', \n",
    "          'player_relative', 'unit_type', 'selected', \n",
    "          'unit_hit_points', 'unit_hit_points_ratio', \n",
    "          'unit_energy', 'unit_energy_ratio', \n",
    "          'unit_shields', 'unit_shields_ratio', \n",
    "          'unit_density', 'unit_density_aa', 'effects']\n",
    "[ [plt.subplot(2, 9, iScreenLayer+1), plt.imshow( obs[0].observation['screen'][iScreenLayer], aspect='equal'), \n",
    "       plt.title(titles[iScreenLayer]), plt.axis('off')] \n",
    " for iScreenLayer in range(numScreenLayers) ]\n",
    "\n",
    "# playerID, unit_type, selected, unit_hit_points, unit_hit_points_ratio\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAANSCAYAAABiOI9AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHrNJREFUeJzt3V+sZWd93+Hvrx7/SUgaA6GWhWlxOxbIF8WgETUCoQSXlCQo9gWioLSyIktWJVqRaarUyU2VqpHCTRwuolQWkMwFCSAn1BaKSCyHKK3UcTCBlD8mYrBA2LI9tMEKQarByduLswlTy9Ycf2fO7DPnPI802mutvY7XT3rlPfrM2nufWWsFAACA5+/vbXsAAACAi5WgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACA0pELebHL5vJ1RV5wIS8JAADwvP3ffCvfXk/N2c67oEF1RV6QfzY3XchLAgAAPG8PrPt3dZ63/AEAAJTOKahm5i0z8xczc2pm7jhfQwEAAFwM6qCamUuS/HqSH09yfZJ3zsz152swAACA/e5c7lC9NsmptdbDa61vJ/lQkpvPz1gAAAD737kE1UuTfO2M/Uc2xwAAAA6FPf+Wv5m5PcntSXJFvn+vLwcAAHDBnMsdqkeTvOyM/Ws2x/4/a6271lrH1lrHLs3l53A5AACA/eVcguqTSa6bmWtn5rIk70hy7/kZCwAAYP+r3/K31np6Zv5tkj9IckmSD6y1Pn/eJgMAANjnzukzVGut30/y++dpFgAAgIvKOf1iXwAAgMNMUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlM4aVDPzgZk5PTOfO+PYi2bmvpn50ubxhXs7JgAAwP6zmztUv5XkLc84dkeS+9da1yW5f7MPAABwqJw1qNZaf5LkL59x+OYkJzbbJ5Lccp7nAgAA2Pfaz1BdtdZ6bLP9eJKrztM8AAAAF41z/lKKtdZKsp7r+Zm5fWYenJkHv5OnzvVyAAAA+0YbVE/MzNVJsnk8/VwnrrXuWmsdW2sduzSXl5cDAADYf9qgujfJrZvtW5Pcc37GAQAAuHjs5mvTfyfJ/0zyipl5ZGZuS/IrSd48M19K8s83+wAAAIfKkbOdsNZ653M8ddN5ngUAAOCics5fSgEAAHBYCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACA0pFtDwDbdurOG/f8GkePn9zzawAAcOG5QwUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAApbMG1cy8bGY+MTNfmJnPz8y7N8dfNDP3zcyXNo8v3PtxAQAA9o/d3KF6OsnPrbWuT3JjknfNzPVJ7khy/1rruiT3b/YBAAAOjbMG1VrrsbXWn222v5nkoSQvTXJzkhOb004kuWWvhgQAANiPntdnqGbm5UleneSBJFettR7bPPV4kqvO62QAAAD73K6DamZ+IMnvJvnZtdZfnfncWmslWc/xc7fPzIMz8+B38tQ5DQsAALCf7CqoZubS7MTUB9dav7c5/MTMXL15/uokp5/tZ9dad621jq21jl2ay8/HzAAAAPvCbr7lb5K8P8lDa61fPeOpe5Pcutm+Nck95388AACA/evILs55fZJ/neSzM/OZzbFfTPIrST4yM7cl+WqSt+/NiAAAAPvTWYNqrfU/ksxzPH3T+R0HAADg4vG8vuUPAACA79nNW/7gQDt6/OS2RwAA4CLlDhUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABA6ci2B4BtO3XnjXt+jaPHT+75NQAAuPDcoQIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgd2fYAsG1Hj5/c9ggAAFyk3KECAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACA0pFtDwDbdurOG/f8GkePn9zzawDAYXMh/g5v+Hv/cHGHCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASke2PQBs29HjJ7c9AgAAFyl3qAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKR7Y9AGzbqTtv3PNrHD1+cs+vAQDAhecOFQAAQElQAQAAlM4aVDNzxcz86cz8+cx8fmZ+aXP82pl5YGZOzcyHZ+ayvR8XAABg/9jNHaqnkrxprfWqJDckecvM3JjkPUnuXGsdTfKNJLft3ZgAAAD7z1mDau34683upZs/K8mbkty9OX4iyS17MiEAAMA+tavPUM3MJTPzmSSnk9yX5MtJnlxrPb055ZEkL92bEQEAAPanXQXVWutv1lo3JLkmyWuTvHK3F5iZ22fmwZl58Dt5qhwTAABg/3le3/K31noyySeSvC7JlTPz3d9jdU2SR5/jZ+5aax1bax27NJef07AAAAD7yW6+5e8lM3PlZvv7krw5yUPZCau3bU67Nck9ezUkAADAfnTk7Kfk6iQnZuaS7ATYR9ZaH5uZLyT50Mz8lySfTvL+PZwTAABg3zlrUK21/leSVz/L8Yez83kqAACAQ+l5fYYKAACA7xFUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAApSPbHgC27ejxk9seAQCAi5Q7VAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFA6su0BYNtO3Xnjnl/j6PGTe34NADhsvvwv/+u2R3hW/+L4DdsegQvIHSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACAkqACAAAoCSoAAICSoAIAACgJKgAAgJKgAgAAKAkqAACA0pFtDwAAAI1/8uF/s+0RntXRnNz2CFxA7lABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUjmx7AAAAaBw9fnLbI4A7VAAAAC1BBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFA6su0BYNuOHj+57REAALhIuUMFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUDqy7QFg207deeOeX+Po8ZN7fg0AAC48d6gAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKggoAAKAkqAAAAEqCCgAAoCSoAAAASoIKAACgJKgAAABKR7Y9AGzb0eMntz0CAAAXKXeoAAAASoIKAACgtOugmplLZubTM/Oxzf61M/PAzJyamQ/PzGV7NyYAAMD+83zuUL07yUNn7L8nyZ1rraNJvpHktvM5GAAAwH63q6CamWuS/GSS9232J8mbkty9OeVEklv2YkAAAID9ard3qH4tyc8n+dvN/ouTPLnWenqz/0iSlz7bD87M7TPz4Mw8+J08dU7DAgAA7CdnDaqZeWuS02utTzUXWGvdtdY6ttY6dmkub/4TAAAA+9Jufg/V65P81Mz8RJIrkvz9JO9NcuXMHNncpbomyaN7NyYAAMD+c9Y7VGutX1hrXbPWenmSdyT5o7XWTyf5RJK3bU67Nck9ezYlAADAPnQuv4fqPyb59zNzKjufqXr/+RkJAADg4rCbt/z9nbXWHyf54832w0lee/5HAgAAuDicyx0qAACAQ01QAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUBBUAAEBJUAEAAJQEFQAAQElQAQAAlAQVAABASVABAACUjuzmpJn5SpJvJvmbJE+vtY7NzIuSfDjJy5N8Jcnb11rf2JsxAQAA9p/nc4fqR9daN6y1jm3270hy/1rruiT3b/YBAAAOjXN5y9/NSU5stk8kueXcxwEAALh47DaoVpI/nJlPzcztm2NXrbUe22w/nuSq8z4dAADAPrarz1AlecNa69GZ+QdJ7puZL5755Fprzcx6th/cBNjtSXJFvv+chgUAANhPdnWHaq316ObxdJKPJnltkidm5uok2Tyefo6fvWutdWytdezSXH5+pgYAANgHzhpUM/OCmfnB724n+bEkn0tyb5JbN6fdmuSevRoSAABgP9rNW/6uSvLRmfnu+b+91vr4zHwyyUdm5rYkX03y9r0bEwAAYP85a1CttR5O8qpnOf5/kty0F0MBAABcDM7la9MBAAAONUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAAKVdBdXMXDkzd8/MF2fmoZl53cy8aGbum5kvbR5fuNfDAgAA7Ce7vUP13iQfX2u9MsmrkjyU5I4k96+1rkty/2YfAADg0DhrUM3MDyV5Y5L3J8la69trrSeT3JzkxOa0E0lu2ashAQAA9qPd3KG6NsnXk/zmzHx6Zt43My9IctVa67HNOY8nuerZfnhmbp+ZB2fmwe/kqfMzNQAAwD6wm6A6kuQ1SX5jrfXqJN/KM97et9ZaSdaz/fBa66611rG11rFLc/m5zgsAALBv7CaoHknyyFrrgc3+3dkJrCdm5uok2Tye3psRAQAA9qezBtVa6/EkX5uZV2wO3ZTkC0nuTXLr5titSe7ZkwkBAAD2qSO7PO/fJfngzFyW5OEkP5OdGPvIzNyW5KtJ3r43IwIAAOxPuwqqtdZnkhx7lqduOr/jAAAAXDx2+3uoAAAAeAZBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAACVBBQAAUBJUAAAApVlrXbiLzXw9yVef5akfTvK/L9gg7DfW//Cy9oeXtT/crP/hZe0Pt4tt/f/RWuslZzvpggbVcw4x8+Ba69i252A7rP/hZe0PL2t/uFn/w8vaH24Hdf295Q8AAKAkqAAAAEr7Jaju2vYAbJX1P7ys/eFl7Q836394WfvD7UCu/774DBUAAMDFaL/coQIAALjobD2oZuYtM/MXM3NqZu7Y9jzsnZn5wMycnpnPnXHsRTNz38x8afP4wm3OyN6YmZfNzCdm5gsz8/mZeffmuPU/BGbmipn505n58836/9Lm+LUz88Dm9f/DM3PZtmdlb8zMJTPz6Zn52Gbf2h8SM/OVmfnszHxmZh7cHPPafwjMzJUzc/fMfHFmHpqZ1x3Utd9qUM3MJUl+PcmPJ7k+yTtn5vptzsSe+q0kb3nGsTuS3L/Wui7J/Zt9Dp6nk/zcWuv6JDcmedfm/3Xrfzg8leRNa61XJbkhyVtm5sYk70ly51rraJJvJLltizOyt96d5KEz9q394fKja60bzvi6bK/9h8N7k3x8rfXKJK/KzmvAgVz7bd+hem2SU2uth9da307yoSQ3b3km9sha60+S/OUzDt+c5MRm+0SSWy7oUFwQa63H1lp/ttn+ZnZeVF8a638orB1/vdm9dPNnJXlTkrs3x63/ATUz1yT5ySTv2+xPrP1h57X/gJuZH0ryxiTvT5K11rfXWk/mgK79toPqpUm+dsb+I5tjHB5XrbUe22w/nuSqbQ7D3puZlyd5dZIHYv0Pjc1bvj6T5HSS+5J8OcmTa62nN6d4/T+4fi3Jzyf5283+i2PtD5OV5A9n5lMzc/vmmNf+g+/aJF9P8pubt/u+b2ZekAO69tsOKvg7a+crJ33t5AE2Mz+Q5HeT/Oxa66/OfM76H2xrrb9Za92Q5JrsvDvhlVseiQtgZt6a5PRa61PbnoWtecNa6zXZ+XjHu2bmjWc+6bX/wDqS5DVJfmOt9eok38oz3t53kNZ+20H1aJKXnbF/zeYYh8cTM3N1kmweT295HvbIzFyanZj64Frr9zaHrf8hs3nLxyeSvC7JlTNzZPOU1/+D6fVJfmpmvpKdt/W/KTufq7D2h8Ra69HN4+kkH83OP6h47T/4HknyyFrrgc3+3dkJrAO59tsOqk8muW7zbT+XJXlHknu3PBMX1r1Jbt1s35rkni3Owh7ZfGbi/UkeWmv96hlPWf9DYGZeMjNXbra/L8mbs/M5uk8kedvmNOt/AK21fmGtdc1a6+XZ+Tv+j9ZaPx1rfyjMzAtm5ge/u53kx5J8Ll77D7y11uNJvjYzr9gcuinJF3JA137rv9h3Zn4iO++vviTJB9Zav7zVgdgzM/M7SX4kyQ8neSLJf0ry35J8JMk/TPLVJG9faz3ziyu4yM3MG5L89ySfzfc+R/GL2fkclfU/4Gbmn2bnw8eXZOcf8j6y1vrPM/OPs3PX4kVJPp3kX621ntrepOylmfmRJP9hrfVWa384bNb5o5vdI0l+e631yzPz4njtP/Bm5obsfBnNZUkeTvIz2fwdkAO29lsPKgAAgIvVtt/yBwAAcNESVAAAACVBBQAAUBJUAAAAJUEFAABQElQAAAAlQQUAAFASVAAAAKX/B6T5/ISTdYSkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe00a5ba7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow( obs[0].observation['screen'][14])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-map layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfecd1ac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numMinimapLayers = obs[0].observation['minimap'].shape[0]\n",
    "plt.figure(figsize=(19,10))\n",
    "titles = ['heigh_map', 'visibility_map', 'creep', 'camera', 'player_id', 'player_relative', 'selected']\n",
    "[ [plt.subplot(1, 8, iMinimapLayer+1), plt.imshow( obs[0].observation['minimap'][iMinimapLayer], aspect='equal'), \n",
    "       plt.title(titles[iMinimapLayer]), plt.axis('off')] \n",
    " for iMinimapLayer in range(numMinimapLayers) ]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe00a5ba128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow( obs[0].observation['minimap'][5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "envParams = { 'screenResX': 64,\n",
    "             'screenResY': 64, \n",
    "             'screenResX_minimap': 32,\n",
    "             'screenResY_minimap': 32,\n",
    "             'visualizeFlag': True,\n",
    "             'simultaneousEnvironments': 1,\n",
    "             'screenChannelsToKeep': [ 4, 5, 6, 7, 8, 9 ], # player_ID, player_relative, unit_type, selected, unit_hit_points, unit_hit_points_ratio\n",
    "             'screenChannelsRetained': 6,\n",
    "             \n",
    "             #'allowedActionIDs': [ 0, 3, 7, 331, 12, 274], # noOp, select_rect, select_army, move_scren, attack_screen, hold_position\n",
    "             #'allowedActionIDRequiresModifier': [ 0, 1, 1, 1, 1, 1 ],            \n",
    "             #'allowedActionIDRequiresLocation': [ 0, 2, 0, 1, 1, 0 ],            \n",
    "             #'prunedActionSpaceSize': 6,\n",
    "\n",
    "             \n",
    "             'allowedActionIDs': [ 3, 12 ], # select_rect, attack_screen\n",
    "             'allowedActionIDRequiresModifier': [ 1, 1 ],            \n",
    "             'allowedActionIDRequiresLocation': [ 2, 1 ],       \n",
    "\n",
    "             #'allowedActionIDs': [ 7, 12 ], # select_army, attack_screen\n",
    "             #'allowedActionIDRequiresModifier': [ 1, 1 ],            \n",
    "             #'allowedActionIDRequiresLocation': [ 0, 1 ],       \n",
    "\n",
    "             'prunedActionSpaceSize': 2,\n",
    "             'actionArgumentSize': 4, \n",
    "             \n",
    "             'nonVisualInputLength': 13,\n",
    "             'nTrajectorySteps': 35,\n",
    "             'futureDiscountRate': 1,\n",
    "             'stepTypeFirst': 0,\n",
    "             'stepTypeMid': 1,\n",
    "             'stepTypeLast': 2,\n",
    "            }\n",
    "\n",
    "# sanity check environment parameter definition\n",
    "assert ( envParams['prunedActionSpaceSize'] == len(envParams['allowedActionIDs']) \\\n",
    "            == len(envParams['allowedActionIDRequiresModifier']) \\\n",
    "            == len(envParams['allowedActionIDRequiresLocation']) )\n",
    "assert ( envParams['screenChannelsRetained'] == len(envParams['screenChannelsToKeep'] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout, Conv2D, Concatenate, concatenate, LSTM, LeakyReLU, TimeDistributed, CuDNNLSTM\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "modelParams = { 'firstFCNeurons': 512, #8129,\n",
    "                'secondFCNeurons': 2148,# 4096, \n",
    "                'lstmNeurons': 256, \n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CuDNNLSTM\n",
    "# batch dimension do not need to be specified except at predict/train time\n",
    "\n",
    "def build_LSTM_agent ( sequenceSteps = 1 ):\n",
    "\n",
    "    # screen/visual features\n",
    "    inputLayerScreenFeaturesSingleStep = Input( shape = ( sequenceSteps, \n",
    "                                                         envParams['screenChannelsRetained'],\n",
    "                                                         envParams['screenResX'], \n",
    "                                                         envParams['screenResY'] ), \n",
    "                                               dtype=np.float32 )\n",
    "\n",
    "    lstmStateH = Input( shape=( modelParams['lstmNeurons'], ) )\n",
    "    lstmStateC = Input( shape=( modelParams['lstmNeurons'], ) )    \n",
    "    \n",
    "    '''\n",
    "    # non-visual features (e.g., supply, current reward, cumulative score )\n",
    "    auxilaryNonVisualInput = Input ( shape = (\n",
    "        sequenceSteps,\n",
    "        envParams['nonVisualInputLength'],) , dtype=np.float32)\n",
    "    '''\n",
    "\n",
    "    # conv2D input_shape with channels_first order expects input with shape ( samples, channels, rows, cols )\n",
    "    firstConv = TimeDistributed ( \n",
    "                    Conv2D ( filters = 16, kernel_size = 8,\n",
    "                         activation = 'relu', #LeakyReLU(alpha=0.3), #'relu', \n",
    "                         padding = 'same',\n",
    "                         data_format = 'channels_first',\n",
    "                         dilation_rate = 1, strides = 1 ) ) ( inputLayerScreenFeaturesSingleStep )\n",
    "\n",
    "    # input_shape = ( envParams['simultaneousEnvironments'], envParams['screenChannelsRetained'], envParams['screenResX'], envParams['screenResY'] )\n",
    "    secondConv = TimeDistributed ( \n",
    "                    Conv2D ( filters = 32, kernel_size = 4,\n",
    "                         activation = 'relu', #LeakyReLU(alpha=0.3),\n",
    "                         padding = 'same',\n",
    "                         data_format = 'channels_first',\n",
    "                         dilation_rate = 1, strides = 1)\n",
    "                ) ( firstConv )\n",
    "\n",
    "    # screen selection coordinates\n",
    "    firstCoordinateConv = TimeDistributed ( \n",
    "                        Conv2D(1, 3, activation = 'linear', \n",
    "                               padding = 'same', \n",
    "                               data_format = 'channels_first')\n",
    "                    ) (secondConv)\n",
    "    \n",
    "    secondCoordinateConv = TimeDistributed ( \n",
    "                        Conv2D(1, 3, activation = 'linear', \n",
    "                               padding = 'same', \n",
    "                               data_format = 'channels_first')\n",
    "                    ) (secondConv)\n",
    "        \n",
    "    # flatten conv output to flat vector \n",
    "    flattenedConvOutput = TimeDistributed(Flatten()) (secondConv)\n",
    "\n",
    "    # combine visual and non-visual features\n",
    "    # screenAndAuxiliary = concatenate([auxilaryNonVisualInput, flattenedConvOutput], axis = 1)\n",
    "\n",
    "    # first dense layer\n",
    "    firstFC = TimeDistributed ( Dense ( modelParams['firstFCNeurons'], activation = 'linear' )) ( flattenedConvOutput )\n",
    "\n",
    "    # final dense layer\n",
    "    finalLayer, internalState1, internalState2 = \\\n",
    "                                  CuDNNLSTM ( modelParams['lstmNeurons'], \n",
    "                                        return_state = True, \n",
    "                                        return_sequences=True ) \\\n",
    "        ( firstFC, initial_state = [lstmStateH, lstmStateC] )\n",
    "\n",
    "    # outputs\n",
    "    value = TimeDistributed( Dense ( 1, activation = 'linear' ) ) ( finalLayer )\n",
    "\n",
    "    actionID = TimeDistributed( Dense ( envParams['prunedActionSpaceSize'], activation = 'softmax' ) ) ( finalLayer )\n",
    "\n",
    "    # combine visual and non-visual features -- concatenation necessary since loss function is applied to all outputs otherwise causing a dimensionality mismatch\n",
    "    #finalLayerConcat = TimeDistributed( Concatenate(axis = 2)) ( value, actionID, actionPositionArgX1, actionPositionArgY1, actionPositionArgX2, actionPositionArgY2 ) )\n",
    "    finalLayerConcat = concatenate([ value, actionID ], axis=2 )\n",
    "    agentModel = Model ( inputs = [ inputLayerScreenFeaturesSingleStep, lstmStateH, lstmStateC ],\n",
    "                        outputs = [ finalLayerConcat, internalState1, internalState2, \n",
    "                                   firstCoordinateConv, secondCoordinateConv ] )\n",
    "    return agentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CuDNNLSTM\n",
    "# batch dimension do not need to be specified except at predict/train time\n",
    "\n",
    "def build_LSTM_agent_trajectory ( sequenceSteps = 1 ):\n",
    "\n",
    "    # screen/visual features\n",
    "    inputLayerScreenFeaturesSingleStep = Input( shape = ( sequenceSteps, \n",
    "                                                         envParams['screenChannelsRetained'],\n",
    "                                                         envParams['screenResX'], \n",
    "                                                         envParams['screenResY'] ), \n",
    "                                               dtype=np.float32 )\n",
    "\n",
    "    lstmStateH = Input( shape=( modelParams['lstmNeurons'], ) )\n",
    "    lstmStateC = Input( shape=( modelParams['lstmNeurons'], ) )    \n",
    "    \n",
    "    '''\n",
    "    # non-visual features (e.g., supply, current reward, cumulative score )\n",
    "    auxilaryNonVisualInput = Input ( shape = (\n",
    "        sequenceSteps,\n",
    "        envParams['nonVisualInputLength'],) , dtype=np.float32)\n",
    "    '''\n",
    "\n",
    "    # conv2D input_shape with channels_first order expects input with shape ( samples, channels, rows, cols )\n",
    "    firstConv = TimeDistributed ( \n",
    "                    Conv2D ( filters = 16, kernel_size = 8,\n",
    "                         activation = 'relu', #LeakyReLU(alpha=0.3), #'relu', \n",
    "                         padding = 'same',\n",
    "                         data_format = 'channels_first',\n",
    "                         dilation_rate = 1, strides = 1 ) ) ( inputLayerScreenFeaturesSingleStep )\n",
    "\n",
    "    # input_shape = ( envParams['simultaneousEnvironments'], envParams['screenChannelsRetained'], envParams['screenResX'], envParams['screenResY'] )\n",
    "    secondConv = TimeDistributed ( \n",
    "                    Conv2D ( filters = 32, kernel_size = 4,\n",
    "                         activation = 'relu', #LeakyReLU(alpha=0.3),\n",
    "                         padding = 'same',\n",
    "                         data_format = 'channels_first',\n",
    "                         dilation_rate = 1, strides = 1 )\n",
    "                ) ( firstConv )\n",
    "\n",
    "    \n",
    "    # screen selection coordinates\n",
    "    firstCoordinateConv = TimeDistributed ( \n",
    "                        Conv2D(1, 3, activation = 'linear', \n",
    "                               padding = 'same', \n",
    "                               data_format = 'channels_first')\n",
    "                    ) (secondConv)\n",
    "    \n",
    "    secondCoordinateConv = TimeDistributed ( \n",
    "                        Conv2D(1, 3, activation = 'linear', \n",
    "                               padding = 'same', \n",
    "                               data_format = 'channels_first')\n",
    "                    ) (secondConv)\n",
    "    \n",
    "    \n",
    "    # flatten conv output to flat vector \n",
    "    flattenedConvOutput = TimeDistributed(Flatten()) (secondConv)\n",
    "\n",
    "    # combine visual and non-visual features\n",
    "    # screenAndAuxiliary = concatenate([auxilaryNonVisualInput, flattenedConvOutput], axis = 1)\n",
    "\n",
    "    # first dense layer\n",
    "    firstFC = TimeDistributed ( Dense ( modelParams['firstFCNeurons'], activation = 'linear' )) ( flattenedConvOutput )\n",
    "\n",
    "    # final dense layer\n",
    "    finalLayer = CuDNNLSTM ( modelParams['lstmNeurons'], return_sequences=True ) \\\n",
    "                        ( firstFC, initial_state = [lstmStateH, lstmStateC] )\n",
    "\n",
    "    # outputs\n",
    "    value = TimeDistributed( Dense ( 1, activation = 'linear' ) ) ( finalLayer )\n",
    "\n",
    "    actionID = TimeDistributed( Dense ( envParams['prunedActionSpaceSize'], activation = 'softmax' ) ) ( finalLayer )\n",
    "    \n",
    "\n",
    "    agentModel = Model ( inputs = [ inputLayerScreenFeaturesSingleStep, lstmStateH, lstmStateC ],\n",
    "                        outputs = [ value, actionID, firstCoordinateConv, secondCoordinateConv ] )\n",
    "    return agentModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function & Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentModelOneStep = build_LSTM_agent(1)\n",
    "agentModelTrajectory = build_LSTM_agent_trajectory(envParams['nTrajectorySteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def placeholder_loss ( y_true, y_pred ):    \n",
    "    combinedLoss =  0 * y_true + 0 * y_pred\n",
    "    return combinedLoss\n",
    "\n",
    "def compute_trajectory_loss ( y_true, y_pred ):\n",
    "    combinedLoss =  y_true - 0 * y_pred\n",
    "    return combinedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opti = optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)#, clipvalue=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 6, 64, 64) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 1, 16, 64, 64 6160        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 1, 32, 64, 64 8224        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 1, 131072)    0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 1, 512)       67109376    time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        [(None, 1, 256), (No 788480      time_distributed_6[0][0]         \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 1, 1)         257         cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 1, 2)         514         cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 3)         0           time_distributed_7[0][0]         \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 1, 1, 64, 64) 289         time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 1, 1, 64, 64) 289         time_distributed_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 67,913,589\n",
      "Trainable params: 67,913,589\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agentModelOneStep.compile ( optimizer = opti, loss = placeholder_loss)\n",
    "agentModelOneStep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 35, 6, 64, 64 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 35, 16, 64, 6 6160        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 35, 32, 64, 6 8224        time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 35, 131072)   0           time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 35, 512)      67109376    time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)        (None, 35, 256)      788480      time_distributed_14[0][0]        \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 35, 1)        257         cu_dnnlstm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 35, 2)        514         cu_dnnlstm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 35, 1, 64, 64 289         time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 35, 1, 64, 64 289         time_distributed_10[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 67,913,589\n",
      "Trainable params: 67,913,589\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agentModelTrajectory.compile ( optimizer = opti, loss = compute_trajectory_loss)\n",
    "agentModelTrajectory.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_actor_agent ( targetModel, sourceModel):\n",
    "    # copy weights    \n",
    "    targetModel.set_weights(sourceModel.get_weights())\n",
    "    # compile model\n",
    "    targetModel.compile( optimizer = opti, loss = placeholder_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Utilization Estimation\n",
    "useful for determining limit of simultaneous agents per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Needed:  6.38708456  -- CPU Memory Needed:  0.003072\n"
     ]
    }
   ],
   "source": [
    "totalModelParams = 79838557 # 175487534 # FC 8129, FC 4096, FC 2148\n",
    "bitsPerModelParam = 32\n",
    "gradientsMultiplier = 2\n",
    "bitsPerObservation = ( obs[0].observation['screen'].nbytes + obs[0].observation['minimap'].nbytes ) * 8\n",
    "numSimultaneousAgents = 10\n",
    "gpuMemoryUsageGB = ( totalModelParams * bitsPerModelParam ) * gradientsMultiplier * numSimultaneousAgents / 8e9\n",
    "ramMemoryUsageGB = bitsPerObservation * numSimultaneousAgents / 8e9\n",
    "print ( 'GPU Memory Needed: ', gpuMemoryUsageGB , ' -- CPU Memory Needed: ', ramMemoryUsageGB )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility/Helper Functions invoked from training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO is obs for multiple environments multi-dimensional ? \n",
    "\n",
    "# extract hand-chosen subset from full raw state -- 6 screen layers &  [ cumulative_score, reward, supply ]\n",
    "def preprocess_observation_to_extract_input_data (obs, envParams):\n",
    "    screenLayers = np.zeros( ( envParams['screenChannelsRetained'],\n",
    "                               envParams['screenResX'],\n",
    "                               envParams['screenResY'] ) )\n",
    "    \n",
    "    screenLayers = np.zeros( ( envParams['screenChannelsRetained'],\n",
    "                               envParams['screenResX'],\n",
    "                               envParams['screenResY'] ) )\n",
    "\n",
    "    \n",
    "    for iLayer in range( envParams['screenChannelsRetained'] ):\n",
    "        screenLayers[ iLayer, :, : ] = obs.observation['screen'][envParams['screenChannelsToKeep'][iLayer]]\n",
    "    \n",
    "    # extract cumulative_score, reward, and supply utilization information for players\n",
    "    auxiliaryData = np.array( [ obs.observation['score_cumulative'][0], \n",
    "                                           obs.reward] \\\n",
    "                                         + [supplyInfo for supplyInfo in obs.observation['player']], dtype=np.float32 )\n",
    "    # reshape so that it can be concatenated with flattened convolutional output\n",
    "    auxiliaryData = np.expand_dims(auxiliaryData, axis=0)\n",
    "    \n",
    "    return screenLayers, auxiliaryData\n",
    "\n",
    "# split the outputs of the last concatenated layer among their respective variables\n",
    "def decompose_concatenated_outputs ( outputs ):\n",
    "    outputsDict = { 'value': outputs[0][0], 'selectedActionDistribution': outputs[0][1:envParams['prunedActionSpaceSize']+1],\n",
    "                    'actionPositionArgX1': 0, 'actionPositionArgY1': 0,\n",
    "                    'actionPositionArgX2': 0, 'actionPositionArgY2': 0 }\n",
    "    assert( np.isclose( np.sum( outputsDict['selectedActionDistribution'] ), 1, 1e5 ) )\n",
    "    return outputsDict\n",
    "\n",
    "# mask unusable actions [ and re-normalize remaining valid actions ]\n",
    "def mask_unavailable_actions ( obs, outputsDict ):\n",
    "    actionMask = np.zeros( envParams['prunedActionSpaceSize'] )\n",
    "    for iAction in range( envParams['prunedActionSpaceSize'] ):\n",
    "        if envParams['allowedActionIDs'][iAction] in obs[0].observation['available_actions']:\n",
    "            actionMask[ iAction ] = 1\n",
    "    outputsDict['selectedActionDistribution'] *= actionMask\n",
    "    outputsDict['selectedActionDistribution'] = 1.0 / ( np.sum( outputsDict['selectedActionDistribution'] ) + 1e-10) * outputsDict['selectedActionDistribution']\n",
    "    \n",
    "    return outputsDict\n",
    "\n",
    "# sample an action using the probabilities assigned to each action by the agent (masked by available actions ) \n",
    "def sample_action ( actionProbabiltiesInCurrentState ) :\n",
    "    availableActions = list( range( envParams['prunedActionSpaceSize'] )) \n",
    "    chosenAction = stats.rv_discrete( values = (availableActions, actionProbabiltiesInCurrentState) ).rvs( size = 1)    \n",
    "    return chosenAction[0]\n",
    "   \n",
    "# sample an action using the probabilities assigned to each action by the agent (masked by available actions ) \n",
    "def sample_coordinates ( outputsDict, firstPointOut, secondPointOut ) :\n",
    "    \n",
    "    def _sample_coordinate ( mapShapeProbabilities ):\n",
    "        flattenedScreenProbabilities = np.squeeze( mapShapeProbabilities ).reshape( ( envParams['screenResX'] * envParams['screenResX'], 1) )\n",
    "        flattenedScreenProbabilities /= ( np.sum(mapShapeProbabilities) )\n",
    "        \n",
    "        if not np.allclose(np.sum(flattenedScreenProbabilities), 1):\n",
    "            flattenedScreenProbabilities[np.argmax(flattenedScreenProbabilities)] += 1.0 - np.sum(flattenedScreenProbabilities)\n",
    "            print('fixed sum = ', np.sum(flattenedScreenProbabilities) )\n",
    "            print(np.allclose(np.sum(flattenedScreenProbabilities), 1))\n",
    "            \n",
    "        if not np.allclose(np.sum(flattenedScreenProbabilities), 1):\n",
    "            np.savetxt('outputProbs.txt', flattenedScreenProbabilities, delimiter=',')\n",
    "            #chosenPoint = [ np.random.randint(envParams['screenResX'] * envParams['screenResY']) ]\n",
    "            raise Exception('grrr')        \n",
    "            \n",
    "        availableCoordinates = list( range( envParams['screenResX'] * envParams['screenResY'] )) \n",
    "\n",
    "        chosenPoint = stats.rv_discrete( values = (availableCoordinates, flattenedScreenProbabilities) ).rvs( size = 1)        \n",
    "        \n",
    "        maxCoord = np.unravel_index( chosenPoint[0], (envParams['screenResX'], envParams['screenResY']))\n",
    "        return maxCoord\n",
    "    \n",
    "    maxCoords1 = _sample_coordinate ( firstPointOut )\n",
    "    maxCoords2 = _sample_coordinate ( secondPointOut )\n",
    "    outputsDict['actionPositionArgX1'] = maxCoords1[0]\n",
    "    outputsDict['actionPositionArgY1'] = maxCoords1[1]\n",
    "    outputsDict['actionPositionArgX2'] = maxCoords2[0]\n",
    "    outputsDict['actionPositionArgY2'] = maxCoords2[1]\n",
    "    return outputsDict\n",
    "\n",
    "def safe_log(x):\n",
    "    return np.where(np.isclose(x,0), 0, np.log(x))\n",
    "\n",
    "# if a spatial action is selected, augment the action with arguments for spatial coordinates\n",
    "def create_sc2_action_from_args ( outputsDict ):\n",
    "    try:\n",
    "        chosenAction = sample_action ( outputsDict['selectedActionDistribution'] )\n",
    "    except:\n",
    "        chosenAction = np.argmax( outputsDict['selectedActionDistribution'] )\n",
    "\n",
    "    actionArguments = []\n",
    "    if envParams['allowedActionIDRequiresLocation'][chosenAction] == 1:\n",
    "        actionArguments = [ [ outputsDict['actionPositionArgX1'],  outputsDict['actionPositionArgY1'] ]]\n",
    "    elif envParams['allowedActionIDRequiresLocation'][chosenAction] == 2:\n",
    "        actionArguments = [[ outputsDict['actionPositionArgX1'],  outputsDict['actionPositionArgY1'] ],\n",
    "                           [ outputsDict['actionPositionArgX2'],  outputsDict['actionPositionArgY2'] ]]\n",
    "    if envParams['allowedActionIDRequiresModifier'][chosenAction]:\n",
    "        actionArguments.insert(0, [1])\n",
    "        \n",
    "    return envParams['allowedActionIDs'][chosenAction], actionArguments, chosenAction\n",
    "\n",
    "# print the exptected argument structure for each element in the input list of functionIDs\n",
    "def print_action_template ( functionIDs ):\n",
    "    print ( '%20s : %3s %23s *%s*' % ('NAME', 'ID', 'ARGUMENTS', 'DETAIL'))\n",
    "    [ print ( '%21s : %3s %23s *%s*' % ( actions.FUNCTIONS[functionID].name, \\\n",
    "                                functionID, \\\n",
    "                                [ [size for size in arg.sizes] for arg in actions.FUNCTIONS[functionID].args ], \\\n",
    "                                actions.FUNCTIONS[functionID] ) ) \\\n",
    "          for functionID in functionIDs ];\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Trajectories [ observe, act, & advance simulation ], \n",
    "## Use rewards & values to compute advantages and Train\n",
    "\n",
    "https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda3\r\n",
      "episode_scores_25.txt\r\n",
      "model_weights_25.h5\r\n",
      "Nvidia_Cloud_EULA.pdf\r\n",
      "pysc2\r\n",
      "sc2DL\r\n",
      "sc2-rl-notebook-fixed-loss-lstm-working-xy-map.ipynb\r\n",
      "sc2-rl-notebook-fixed-loss-lstm-working-xy-map-non-queued-actions-safe-log.ipynb\r\n",
      "src\r\n",
      "StarCraftII\r\n",
      "tutorials\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionHistory = np.zeros( ( envParams['prunedActionSpaceSize'], ) )\n",
    "episodeScores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentModelTrajectory.load_weights('model_weights_25.h5')\n",
    "#episodeScores = np.loadtxt('episode_scores_25.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:84: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last reward :21\n",
      "last reward :21\n",
      "last reward :11\n",
      "last reward :29\n",
      "last reward :1\n",
      "last reward :26\n",
      "last reward :11\n",
      "last reward :36\n",
      "last reward :28\n",
      "last reward :21\n",
      "last reward :1\n",
      "last reward :1\n",
      "last reward :11\n",
      "last reward :1\n",
      "last reward :1\n",
      "last reward :-9\n",
      "last reward :1\n",
      "last reward :21\n",
      "last reward :1\n",
      "last reward :1\n",
      "last reward :26\n",
      "last reward :-9\n",
      "last reward :21\n",
      "last reward :-9\n",
      "last reward :26\n",
      "last reward :36\n",
      "last reward :21\n",
      "last reward :11\n",
      "last reward :11\n",
      "last reward :-9\n",
      "last reward :-5\n",
      "last reward :11\n",
      "last reward :-9\n",
      "last reward :11\n",
      "last reward :21\n",
      "last reward :36\n",
      "last reward :11\n",
      "last reward :-9\n",
      "last reward :46\n",
      "last reward :11\n",
      "last reward :36\n",
      "last reward :1\n",
      "last reward :21\n",
      "last reward :36\n",
      "last reward :1\n",
      "last reward :-5\n",
      "last reward :-9\n",
      "last reward :36\n",
      "last reward :26\n",
      "last reward :11\n",
      "saving model & episode scores\n",
      "last reward :1\n",
      "last reward :21\n",
      "last reward :-9\n",
      "last reward :26\n",
      "last reward :-9\n",
      "last reward :11\n",
      "last reward :-9\n",
      "last reward :1\n",
      "last reward :26\n",
      "last reward :1\n",
      "last reward :-6\n",
      "last reward :-9\n",
      "last reward :11\n",
      "last reward :21\n",
      "last reward :21\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "nTrajectoriesToTrain = 100\n",
    "\n",
    "debugFlag = False\n",
    "\n",
    "outputDimensionality = 1 + envParams['prunedActionSpaceSize'] + envParams['actionArgumentSize'] # 1 = value estimate [ scaler ]\n",
    "\n",
    "lstmStateHOneStep = np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "lstmStateCOneStep = np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "\n",
    "# placeholders for trajectory variables\n",
    "# screen layers\n",
    "worldScreenStates = np.zeros( ( envParams['nTrajectorySteps'],  envParams['screenChannelsRetained'],\n",
    "                               envParams['screenResX'], envParams['screenResY'] ))\n",
    "# non-visual state data\n",
    "worldAuxiliaryData = np.zeros( (envParams['nTrajectorySteps'], envParams['nonVisualInputLength'] ))\n",
    "\n",
    "# placeholders for populating training / model.fit\n",
    "y_pred = np.zeros( ( envParams['nTrajectorySteps'], outputDimensionality), dtype=np.float32)\n",
    "y_true = np.zeros( ( envParams['nTrajectorySteps'], outputDimensionality), dtype=np.float32 )\n",
    "\n",
    "nStepReturns = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.float32 ) # TODO: 'simultaneousEnvironments'\n",
    "valueEstimates = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.float32 ) # TODO: 'simultaneousEnvironments'\n",
    "rewards = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.float32 ) # TODO: 'simultaneousEnvironments'\n",
    "actionChosenIndexes = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.int32 ) # TODO: 'simultaneousEnvironments'\n",
    "actionDistributions = np.zeros( ( envParams['nTrajectorySteps'], envParams['prunedActionSpaceSize'] ), dtype=np.float32 ) # TODO: 'simultaneousEnvironments'\n",
    "\n",
    "\n",
    "policyLoss = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.float32 )\n",
    "entropyLoss = np.zeros( ( envParams['nTrajectorySteps'], 1 ), dtype=np.float32 )\n",
    "zz = np.zeros((1, envParams['nTrajectorySteps'], 1, envParams['screenResX'], envParams['screenResY']))\n",
    "\n",
    "# training loop\n",
    "# for i in range( nTrajectoriesToTrain ):\n",
    "while True:    \n",
    "    \n",
    "    trainFlag = True\n",
    "    \n",
    "    if len(episodeScores) > 1 and len(episodeScores) % 25 == 0:\n",
    "        strFilename = 'model_weights_' + str(len(episodeScores)) + '.h5'\n",
    "        if not os.path.isfile(strFilename):\n",
    "            print('saving model & episode scores')\n",
    "            agentModelTrajectory.save_weights(strFilename)\n",
    "            strFilename = 'episode_scores_' + str(len(episodeScores)) + '.txt'\n",
    "            np.savetxt(strFilename, episodeScores, delimiter=',')\n",
    "    \n",
    "    \n",
    "    outputDict = {}\n",
    "    nextValues = []\n",
    "    trajectoryStartStateH = lstmStateHOneStep\n",
    "    trajectoryStartStateC = lstmStateCOneStep\n",
    "    # start = time.time()\n",
    "    for iStep in range ( envParams['nTrajectorySteps'] + 1 ):\n",
    "        \n",
    "        if obs[0].step_type == envParams['stepTypeLast']:\n",
    "            lstmStateHOneStep = np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "            lstmStateCOneStep = np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "\n",
    "            episodeScores += [ obs[0].observation['score_cumulative'][0] ]\n",
    "            print('last reward :' + str ( obs[0].observation['score_cumulative'][0] ))\n",
    "            trainFlag = False\n",
    "            obs = env.step( [ actions.FunctionCall( 0, []  ) ] )\n",
    "            obs = env.step( [ actions.FunctionCall( 0, []  ) ] )\n",
    "            obs = env.step( [ actions.FunctionCall( 0, []  ) ] )\n",
    "            break\n",
    "        \n",
    "\n",
    "        # extract screen features and non-visual state information\n",
    "        screenLayers, auxiliaryData = preprocess_observation_to_extract_input_data (obs[0], envParams)\n",
    "        \n",
    "        scInput = np.expand_dims(np.expand_dims(screenLayers,axis=0),axis=0)        \n",
    "        outputs = agentModelOneStep.predict ( [ scInput, lstmStateHOneStep, lstmStateCOneStep ])\n",
    "        \n",
    "        lstmStateHOneStep = outputs[1]\n",
    "        lstmStateCOneStep = outputs[2]\n",
    "        \n",
    "        firstPointOut = outputs[3]\n",
    "        secondPointOut = outputs[4]\n",
    "        \n",
    "        outputDict = decompose_concatenated_outputs( outputs[0][0] ) # note modified for sequential\n",
    "        \n",
    "        outputsDict = mask_unavailable_actions ( obs, outputDict ) \n",
    "        \n",
    "        outputsDict = sample_coordinates ( outputsDict, firstPointOut, secondPointOut )\n",
    "        \n",
    "        finalAction, actionArguments, actionIndex = create_sc2_action_from_args ( outputDict )\n",
    "       \n",
    "        if debugFlag:\n",
    "            print( '------------------- network outputs -------------------')\n",
    "            print( 'v: %f' %  ( outputDict['value'] ) )\n",
    "            print ( outputDict['selectedActionDistribution'] )\n",
    "            print( 'coordinates (  %.3f, %.3f ) -> ( %.3f, %.3f )' % ( outputDict['actionPositionArgX1'], outputDict['actionPositionArgY1'], \\\n",
    "                                                                         outputDict['actionPositionArgX2'], outputDict['actionPositionArgY2'] ) )\n",
    "            print( '\\n------------------- available actions -------------------' )\n",
    "            print_action_template ( obs[0].observation[\"available_actions\"] ) # # print structure of acceptable args\n",
    "            print( '\\n------------------- selected action -------------------' )\n",
    "            print_action_template ( [finalAction] ) # # print structure of selected action & arguments\n",
    "\n",
    "        \n",
    "        # build arrays needed for training -- worldStates will be inputs, rewards and nextValues are needed for advantage computations\n",
    "        if iStep > 0:\n",
    "            nextValues += [ outputDict['value'] ]\n",
    "        if iStep < envParams['nTrajectorySteps']:\n",
    "            rewards[iStep, :] = obs[0].reward\n",
    "            valueEstimates[iStep, :] = outputDict['value']\n",
    "            actionDistributions[iStep] = outputDict['selectedActionDistribution']\n",
    "            actionChosenIndexes[iStep, :] = [ int( actionIndex ) ]\n",
    "            # coordinate entropy \n",
    "            \n",
    "            worldScreenStates[iStep,:,:,:] = screenLayers\n",
    "            worldAuxiliaryData[iStep,:] = auxiliaryData[0]\n",
    "        \n",
    "        # ask simulation for next game state given our action choice\n",
    "        obs = env.step( [ actions.FunctionCall( finalAction, actionArguments  ) ] )\n",
    "        \n",
    "\n",
    "    # end of trajectory -----\n",
    "    # print('trajectory generation time: ',  str(time.time() - start))    \n",
    "    \n",
    "    if trainFlag:\n",
    "        # compute n-Step returns\n",
    "        for iStep in reversed( range ( envParams['nTrajectorySteps'] ) ) :\n",
    "            if iStep == ( envParams['nTrajectorySteps'] - 1 ) :\n",
    "                nStepReturns[iStep, : ] = nextValues[-1] # final return is the raw reward from the state at the end of the trajectory + 1 timestep\n",
    "            else:\n",
    "                nStepReturns[iStep, : ] = rewards[ iStep ] + envParams['futureDiscountRate'] * nStepReturns[iStep + 1, : ]\n",
    "\n",
    "\n",
    "        # prepare for training loop\n",
    "        advantages = nStepReturns - valueEstimates\n",
    "        valueLoss = np.power( advantages, 2 )/2 \n",
    "\n",
    "        for iStep in range ( envParams['nTrajectorySteps'] ):\n",
    "            policyLoss[ iStep ] = - advantages[ iStep ] * safe_log ( actionDistributions[iStep, actionChosenIndexes[iStep]] )\n",
    "            entropyLoss[ iStep ] = - np.sum( safe_log ( actionDistributions[iStep, :] ) * actionDistributions[iStep, :], axis=0)   \n",
    "\n",
    "        policyLoss = policyLoss\n",
    "        valueLoss = valueLoss\n",
    "        entropyLoss = entropyLoss\n",
    "\n",
    "        combinedLoss = policyLoss + .5 * valueLoss + .1 * entropyLoss\n",
    "        y_true = combinedLoss\n",
    "\n",
    "        y_true = np.expand_dims(y_true.astype(np.float32), axis=0)\n",
    "        xInput = np.expand_dims(worldScreenStates,axis=0)\n",
    "        \n",
    "        lstmStateH = trajectoryStartStateH#np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "        lstmStateC = trajectoryStartStateC#np.zeros((1, modelParams['lstmNeurons']),dtype=np.float32)\n",
    "        \n",
    "        # model fit\n",
    "        # start = time.time()\n",
    "        \n",
    "        agentModelTrajectory.fit( x = [ xInput, lstmStateH, lstmStateC ], \n",
    "                                 y = [ y_true, y_true, zz, zz ], verbose = 0)        \n",
    "        # print('training time: ',  str(time.time() - start))\n",
    "        \n",
    "        # update parameters\n",
    "        # start = time.time()\n",
    "        update_actor_agent ( agentModelOneStep, agentModelTrajectory )        \n",
    "        # print('weight update time: ',  str(time.time() - start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving model')\n",
    "strFilename = 'model_weights_' + str(len(episodeScores)) + '.h5'\n",
    "agentModelTrajectory.save_weights(strFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentMo delTrajectory.load_weights('model_weights_15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(episodeScores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actionHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Action Issue Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action = actions.FunctionCall(0, [])\n",
    "for i in range(10):\n",
    "    #obs = env.step([actions.FunctionCall(0, [])]) # no op\n",
    "    obs = env.step([actions.FunctionCall(12, [[0], [40,15]])]) # attack screen\n",
    "    #obs = env.step([actions.FunctionCall(13, [[0], [25,7]])]) # attack minimap\n",
    "    #obs = env.step([actions.FunctionCall(3, [[1], [0,0], [31,31]])]) # select rect \n",
    "    #obs = env.step([actions.FunctionCall(7, [[1]])]) # select entire army     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched multithreaded dynamic rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCoords1 = np.unravel_index(np.argmax(firstPointOut), (envParams['screenResX'],envParams['screenResY']))\n",
    "maxCoords2 = np.unravel_index(np.argmax(secondPointOut), (envParams['screenResX'],envParams['screenResY']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside the mind of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.squeeze(firstPointOut)\n",
    "yy = np.squeeze(secondPointOut)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(xx)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "a = np.zeros((envParams['screenResX'],envParams['screenResX']))\n",
    "a[outputDict['actionPositionArgX1'],outputDict['actionPositionArgY1']] = 10\n",
    "plt.imshow(xx + a)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(yy)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "a = np.zeros((envParams['screenResX'],envParams['screenResX']))\n",
    "a[outputDict['actionPositionArgX2'],outputDict['actionPositionArgY2']] = 10\n",
    "\n",
    "plt.imshow(yy+a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
